# å¤šå€‹ pipeline åˆ†å±¤æ¶æ§‹ï¼Œä¸¦åœ¨ settings.py è¨­å®šè™•ç†å„ªå…ˆé †åºã€‚
from datetime import datetime
import os, re, json, logging, unicodedata
from .utils.cinema_info import cinema_address_map
from rapidfuzz import fuzz

logger = logging.getLogger(__name__)
logger.setLevel(logging.WARNING)

class MoviescraperPipeline:
    def __init__(self):
        self.address_map = cinema_address_map
        self.spider_cinema_map = {
            'venice': 'å¨å°¼æ–¯å½±åŸ',
            'vs': 'å¨ç§€å½±åŸ',
            'sk': 'æ–°å…‰å½±åŸ',
            'amba': 'åœ‹è³“å½±åŸ',
            'showtimes': 'ç§€æ³°å½±åŸ',
            'sbc': 'æ˜Ÿæ©‹åœ‹éš›å½±åŸ'
        }
        self.title_pool = []

    def process_item(self, item, spider):
        address = self.match_city_address(item['å½±é™¢'])
        item['åœ°å€'] = address
        item['city'] = address[:2]
        item['cinema'] = self.spider_cinema_map.get(spider.name, 'æœªçŸ¥å½±åŸ')
        item['é›»å½±åç¨±'] = self.normalize_title(item.get('é›»å½±åç¨±', ''))
        item['æ—¥æœŸ'] = self.format_date(item.get('æ—¥æœŸ', ''), spider.name)
        item["æ™‚åˆ»è¡¨"] = [t.strip() for t in item["æ™‚åˆ»è¡¨"]]

        # åœ‹è³“å½±åŸ_æ”¾æ˜ ç‰ˆæœ¬æ ¼å¼
        if spider.name == 'amba':
            version = item.get('æ”¾æ˜ ç‰ˆæœ¬', '')
            match = re.search(r'[ï¼ˆ(](.+?)[ï¼‰)]', version)
            item['æ”¾æ˜ ç‰ˆæœ¬'] = match.group(1) or match.group(2) if match else version

        return item

    def match_city_address(self, cinema_name):
        for key in self.address_map:
            if cinema_name.startswith(key) or key in cinema_name:
                return self.address_map[key]

        return 'æœªçŸ¥åœ°å€'

    def normalize_title(self, title):
        # å°‡å…¨å½¢è½‰åŠå½¢ï¼ˆå«æ¨™é»ï¼‰
        title = unicodedata.normalize('NFKC', title)   # å…¨å½¢è½‰åŠå½¢
        title = re.sub(r'[ã€Œã€ã€ã€â€œâ€â€˜â€™:ï¼š_ï¼ãƒ».]', ' ', title)     # ç§»é™¤ä¸­è‹±æ–‡ç¬¦è™Ÿ
        title = re.sub(r'\s+', ' ', title).strip()     # åˆä½µç©ºæ ¼ä¸¦å»é™¤é¦–å°¾ç©ºç™½

        # æ¨¡ç³Šæ¯”å°
        for known in self.title_pool:
            scores = {
                "token_set": fuzz.token_set_ratio(title, known),
                "token_sort": fuzz.token_sort_ratio(title, known),
                "partial": fuzz.partial_ratio(title, known),
                "ratio": fuzz.ratio(title, known),
                "wratio": fuzz.WRatio(title, known)
            }
            best_score = max(scores.values())
            if best_score >= 90:
                return known
            else:
                logging.debug(f"ğŸ§ª tried: '{title}' vs '{known}' â†’ score={best_score}")

        self.title_pool.append(title)
        logging.warning(f"âš ï¸ æœªæ¯”å°æˆåŠŸï¼Œæ–°å¢æ¨™é¡Œï¼š'{title}'")
        return title

    def format_date(self, raw_date, spider_name='unknown'):
        date_str = raw_date.strip()
        today = datetime.today().date()

        if re.fullmatch(r"\d{4}-\d{2}-\d{2}", date_str):
            return date_str

        patterns = [
            {"pattern": r"(\d{4})-(\d{1,2})-(\d{1,2})\(æ˜ŸæœŸ.\)", "year":1, "month":2, "day":3},
            {"pattern": r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥(æ˜ŸæœŸ.)", "year":1, "month":2, "day":3},
            {"pattern": r"(\d{1,2})-(\d{1,2})\(.\)", "year": None, "month":1, "day":2},
            {"pattern": r"(\d{1,2})æœˆ(\d{1,2})æ—¥\(å‘¨.\)", "year": None, "month":1, "day":2},
            {"pattern": r".*?(\d{4})/(\d{1,2})/(\d{1,2})", "year":1, "month":2, "day":3}
        ]

        for p in patterns:
            match = re.search(p["pattern"], date_str)
            if not match:
                continue
            try:
                y = int(match.group(p["year"])) if p["year"] else today.year
                m = int(match.group(p["month"]))
                d = int(match.group(p["day"]))
                dt = datetime(y, m, d).date()
                # è‹¥å·²é â†’ è£œæˆä¸‹ä¸€å¹´
                if dt < today:
                    y += 1
                    dt = datetime(y, m, d).date()
                return f'{dt.strftime("%Y-%m-%d")}'

            except Exception as e:
                logger.warning(f"[{spider_name}] æ—¥æœŸè§£æå¤±æ•—: '{date_str}' â†’ {e}")
                continue

        logger.warning(f"[{spider_name}] ç„¡æ³•è§£ææ—¥æœŸæ ¼å¼: '{date_str}'")
        return raw_date  # å¦‚æœç„¡æ³•è§£æï¼Œå°±åŸæ¨£è¿”å›

# å­˜æª”: data/*_formated.json
class JsonExportPipeline:
    def open_spider(self, spider):
        self.items = []

    def close_spider(self, spider):
        os.makedirs("data", exist_ok=True)
        with open(f"data/{spider.name}_formated.json", "w", encoding="utf-8") as f:
            json.dump(self.items, f, indent=4, ensure_ascii=False)
            print(f"{spider.name}_formated.json saved")

    def process_item(self, item, spider):
        self.items.append(dict(item))
        return item



