from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings
from moviescraper.spiders.amba import AmbassadorSpider
from moviescraper.spiders.showTimes import ShowTimeSpider
from moviescraper.spiders.sk import skSpider
from moviescraper.spiders.vs import vsSpider
from moviescraper.spiders.venice import VeniceSpider

from moviescraper.utils.data_merger import merge_cleaned_outputs

import logging
import time
import json

SPIDER_MAP = {
    'amba': AmbassadorSpider,
    'showtimes': ShowTimeSpider,
    'sk': skSpider,
    'vs': vsSpider,
    'venice': VeniceSpider,
}

def run_all_spiders():
    settings = get_project_settings()
    process = CrawlerProcess(settings)

    report = {}
    for name, spider_cls in SPIDER_MAP.items():
        start = time.time()
        process.crawl(spider_cls)
        report[name] = {'start': start}

    process.start()

    for name in report:
        end = time.time()
        duration = end - report[name]['start']
        minutes, seconds = divmod(duration, 60)
        report[name]['duration'] = f"{int(minutes)} åˆ† {int(seconds)} ç§’"
        report[name]['end'] = end

    print("\nâœ… æ‰€æœ‰çˆ¬èŸ²å®Œæˆï¼ŒåŸ·è¡Œæ™‚é–“å¦‚ä¸‹ï¼š")
    for name, info in report.items():
        print(f"- {name}: {info['duration']}")

    # ğŸ§© åŸ·è¡Œåˆä½µæ¨¡çµ„ï¼ŒæŠŠæ‰€æœ‰ *_formated.json æ•´åˆæˆ all_cleaned.json
    print("\n[MERGE] é–‹å§‹åˆä½µæ‰€æœ‰ cleaned JSON...")
    merge_cleaned_outputs(folder="data", pattern="*_formated.json", output="all_cleaned.json")
    print("[MERGE] âœ… åˆä½µå®Œæˆ â†’ è¼¸å‡º all_cleaned.json")

if __name__ == "__main__":
    logging.getLogger('scrapy').setLevel(logging.DEBUG)  # å¦‚éœ€æ›´è©³ç´°å¯æ”¹æˆ INFO
    run_all_spiders()