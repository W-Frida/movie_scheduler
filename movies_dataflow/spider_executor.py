import time, sys, subprocess
from pathlib import Path
from scrapy.crawler import CrawlerRunner, CrawlerProcess
from scrapy.utils.project import get_project_settings
from moviescraper.spiders import amba, showTimes, sk, vs, venice

SPIDER_MAP = {
    'amba': amba.AmbassadorSpider,
    'showtimes': showTimes.ShowTimeSpider,
    'sk': sk.skSpider,
    'vs': vs.vsSpider,
    'venice': venice.VeniceSpider,
}

class SpiderExecutor:
    def __init__(self):
        self.report = {}

    def run(self, mode="cli", spiders=None):
        if mode == "cli":
            self.run_cli(spiders)
        elif mode == "async":
            self.run_async(spiders)
        elif mode == "subprocess":
            self.run_subprocess(spiders)
        else:
            raise ValueError(f"âŒ ä¸æ”¯æ´çš„åŸ·è¡Œæ¨¡å¼ï¼š{mode}")

    def run_cli(self, spiders=None):
        print("ğŸ–¥ï¸ CLI æ¨¡å¼ â†’ ä½¿ç”¨ CrawlerProcess")
        process = CrawlerProcess(get_project_settings())

        selected = spiders or list(SPIDER_MAP.keys())
        for name in selected:
            spider_cls = SPIDER_MAP.get(name)
            if not spider_cls:
                print(f"âš ï¸ æœªçŸ¥çˆ¬èŸ²åç¨±ï¼š{name}")
                continue
            self.report[name] = {'start': time.time()}
            process.crawl(spider_cls)
            print(f"ğŸ•·ï¸ å·²è¨»å†Šçˆ¬èŸ²ï¼š{name}")

        try:
            print("ğŸš€ Scrapy process å³å°‡å•Ÿå‹•")
            process.start()
            print("âœ… Scrapy process å·²çµæŸ")
        except Exception as e:
            print(f"âš ï¸ CLIæ¨¡å¼ åŸ·è¡Œå¤±æ•—ï¼š{e}")

        self._finish_report()

    def run_async(self, spiders=None):
        print("ğŸŒ éåŒæ­¥æ¨¡å¼ â†’ ä½¿ç”¨ CrawlerRunner")
        from scrapy.utils.reactor import install_reactor
        install_reactor("twisted.internet.asyncioreactor.AsyncioSelectorReactor")
        from twisted.internet import reactor, defer

        selected = spiders or list(SPIDER_MAP.keys())

        @defer.inlineCallbacks
        def _run():
            runner = CrawlerRunner(get_project_settings())

            for name in selected:
                spider_cls = SPIDER_MAP.get(name)
                if not spider_cls:
                    print(f"âš ï¸ æœªçŸ¥çˆ¬èŸ²åç¨±ï¼š{name}")
                    continue
                self.report[name] = {'start': time.time()}
                try:
                    yield runner.crawl(spider_cls)
                    print(f"âœ… {name} åŸ·è¡Œå®Œæˆ")
                except Exception as e:
                    print(f"âš ï¸ asyncæ¨¡å¼ {name} åŸ·è¡Œå¤±æ•—: {e}")

            self._finish_report()
            reactor.callLater(30, reactor.stop)  # æœ€å¤šåŸ·è¡Œ 30 ç§’ # æ’ç¨‹åœæ­¢

        reactor.callWhenRunning(_run) # è¨»å†Š callback (è¨»å†Šæ‰€æœ‰éåŒæ­¥ä»»å‹™)
        reactor.run() # å•Ÿå‹•äº‹ä»¶å¾ªç’° â†’ é–‹å§‹åŸ·è¡Œ _run() è£¡çš„ yield ä»»å‹™


    def run_subprocess(self, spiders=None):
        print("ğŸŒ ä½¿ç”¨ subprocess åŒ…è£ CLI")
        spider_path = Path(__file__)
        args = ["--cli"]
        if spiders:
            args.append("--targets=" + ",".join(spiders))
        result = subprocess.run([sys.executable, str(spider_path)] + args)
        if result.returncode != 0:
            print(f"âš ï¸ subprocess returncode é 0ï¼š{result.returncode}")
        else:
            print("âœ… subprocess åŸ·è¡ŒæˆåŠŸ")

    def _finish_report(self):
        print("\nâœ… æ‰€æœ‰çˆ¬èŸ²å®Œæˆï¼ŒåŸ·è¡Œæ™‚é–“å¦‚ä¸‹ï¼š")
        for name, info in self.report.items():
            end = time.time()
            duration = end - info['start']
            minutes, seconds = divmod(duration, 60)
            print(f"- {name}: {int(minutes)} åˆ† {int(seconds)} ç§’")

# âœ… subprocess å‘¼å«å…¥å£
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="åŸ·è¡Œ Scrapy çˆ¬èŸ²")
    parser.add_argument("--mode", default="cli", choices=["cli", "async", "subprocess"])
    parser.add_argument("--targets", type=str, help="æŒ‡å®šçˆ¬èŸ²åç¨±ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼‰")
    args = parser.parse_args()

    spiders = args.targets.split(",") if args.targets else None
    SpiderExecutor().run(mode=args.mode, spiders=spiders)

